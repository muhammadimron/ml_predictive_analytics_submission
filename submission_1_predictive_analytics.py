# -*- coding: utf-8 -*-
"""Submission 1 - Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T_2amzSHvZPnpOXPjBcQRwVhgOB10lhi

# Data Loading

### Download dataset dari kaggle

> Pengambilan dataset dari kaggle dilakukan menggunakan API kaggle. Dataset diunduh dengan menuliskan kode dengan format nama_pembuat/nama_dataset. Setelah pengunduhan dataset berhasil, dataset kemudian di unzip dan siap digunakan.

> Pertama-tama, mari install package kaggle terlebih dahulu
"""

!pip install kaggle

!mkdir ~/.kaggle

"""> Kemudian mari atur API key kaggle.json"""

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

"""> Setelah itu, mari cari dataset yang diinginkan, dalam hal ini saya memilih dataset dengan keyword pencarian 'car-price'"""

!kaggle datasets list -s car-price

"""> Pilih salah satu dataset yang muncul dan download dengan format nama_pembuat/nama_dataset"""

!kaggle datasets download aleksandrglotov/car-prices-poland --unzip

"""### Import Library & Data Overview"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from sklearn.decomposition import PCA
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler

cars = pd.read_csv('/content/Car_Prices_Poland_Kaggle.csv')
cars.tail()

"""# Exploratory Data Analysis

> Berdasarkan dokumentasi dataset pada website kaggle, dataset ini memiliki column:
*   Unnamed:0: kolom kosong dari dataset (sudah default dari dataset asli)
*   mark: jenis dari mobil
*   model: model dari mobil
*   generation_name: generasi mobil
*   year: tahun mobil diproduksi
*   mileage: jarak tempuh mobil sejak dibeli
*   vol_engine: berat mesin mobil
*   fuel: bensin yang digunakan mobil
*   city: kota mobil diproduksi
*   province: provinsi mobil diproduksi
*   price: harga dari mobil (target)

### Deskripsi Variabel
"""

cars.info()

"""Berdasarkan info diatas, terlihat bahwa
*   terdapat 6 column bertipe object
*   terdapat 5 column numerik bertipe int64




"""

cars.describe()

"""### Data Cleaning

> Langkah pertama adalah menghapus kolom unnamed: 0, karena kolom tersebut hanyalah kolom kosong, jadi tidak diperlukan


"""

cars.drop(columns='Unnamed: 0', inplace=True)
cars.head(2)

"""> Berdasarkan info dataset, jumlah generasi_name tidak sama dengan jumlah kolom lain, hal tersebut menunjukkan terdapat missing value"""

missing = cars.isnull().sum()
missing

"""> Daripada harus menangani missing value untuk 30.000 lebih baris hanya pada satu kolom, alangkah lebih baik jika kolom tersebut dihapus saja."""

cars.drop(columns='generation_name', inplace=True)
cars.head(2)

"""> Berdasarkan fungsi describe(), kolom mileage dan vol_engine memiliki nilai terkecil nol, hal tersebut tidak mungkin terjadi."""

cars.loc[(cars['mileage']==0)]

cars.loc[(cars['vol_engine']==0)]

"""> Jumlah kolom mileage dan vol_engine yang bernilai nol masing-masing adalah 373 dan 1248 baris. Jumlah tersebut sangat kecil jika dibandingkan dengan keseluruhan dataset yaitu sekitar 117.000 baris. Jadi mari hapus baris kolom mileage dan vol_engine yang mempunyai nilai nol."""

cars = cars.loc[(cars[['mileage','vol_engine']]!=0).all(axis=1)]
cars.shape

"""

> Sekarang dataset terlihat rapi, langkah selanjutnya adalah menghapus nilai duplikat jika ada



"""

cars.drop_duplicates(inplace=True)
cars.shape

"""> Setelah ini, coba kita cek kembali kolom numerik dengan fungsi describe() dan info()"""

cars.describe()

cars.info()

"""> Sepertinya tidak ada masalah, selanjutnya mari kita tangani outlier jika memang ada"""

Q1 = cars.quantile(0.25)
Q3 = cars.quantile(0.75)
IQR=Q3-Q1
cars=cars[~((cars<(Q1-1.5*IQR))|(cars>(Q3+1.5*IQR))).any(axis=1)]
cars.shape

"""> Terakhir untuk memudahkan dalam data preprocessing, mari ubah tipe kolom numerik menjadi float64"""

cars['year'] = cars['year'].astype('float64')
cars['mileage'] = cars['mileage'].astype('float64')
cars['vol_engine'] = cars['vol_engine'].astype('float64')

"""> Kemudian kita cek dataset kembali dengan fungsi info() dan describe()"""

cars.info()

cars.describe()

"""> Fyuuuhhh, akhirnya selesai data cleaning

### Univariate Analysis

##### Kolom Kategorical
"""

categorical_col = cars.select_dtypes(['object'])
categorical_col.head(2)

"""> Sebelum analysis setiap fitur, mari siapkan fungsi analysis untuk mengurangi boilerplate kode"""

def feature_analysis(feature):
  count = cars[feature].value_counts()
  percent = 100*cars[feature].value_counts(normalize=True)
  df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
  print(df)
  count.plot(kind='bar', title=feature);

"""> Fitur mark"""

feature_analysis('mark')

"""> Terdapat 23 kategori pada fitur mark, dengan jumlah terbanyak adalah kategori 'opel' dan jumlah paling sedikit adalah 'chevrolet'. Sekitar 20% lebih sampel berada pada kategori 'opel', 'volkswagen', dan 'ford'.

> Fitur model
"""

feature_analysis('model')

"""> Terdapat 290 kategori pada fitur model dengan jumlah terbanyak adalah kategori 'astra' dan paling sedikit adalah kategori 'f150'. Jumlah kategori pada fitur model terlalu banyak sehingga akan berakibat pada pelatihan model, maka mari hapus fitur ini


"""

cars.drop(['model'], inplace=True, axis=1)
cars.head()

"""> Fitur fuel"""

feature_analysis('fuel')

"""> Terdapat 5 kategori pada fitur fuel dengan jumlah terbanyak adalah kategori 'Gasiline' dan paling sedikit adalah kategori 'Electric'. Dapat dilihat 90% lebih sampel merupakan kategori 'Gasoline' dan 'Diesel'

> Fitur city
"""

feature_analysis('city')

"""> Terdapat 4151 kategori dalam fitur city dengan jumlah terbanyak adalah kategori 'Warszawa' dan paling sedikit adalah kategori 'Bledzew'. Jumlah kategori pada fitur city terlalu banyak sehingga akan berakibat pada pelatihan model, maka mari hapus saja fitur city


"""

cars.drop(['city'], inplace=True, axis=1)
cars.head()

"""> Fitur province"""

feature_analysis('province')

"""> Terdapat 23 kategori pada fitur province dengan jumlah sampel terbanyak berada pada kategori 'Mazowieckie' dan paling sedikit adalah kategori 'Northern-Westfalen'. Dapat dilihat 30% lebih sampel berasal dari kategori 'Mazowieckie', 'Slaskie', dan 'Wielkopolskie'.

##### Kolom Numerik
"""

numerical_col = cars.select_dtypes(['int', 'float'])
numerical_col.head(2)

numerical_col.hist(bins=50, figsize=(20,15))
plt.show()

"""> Berdasarkan histogram diatas terutama pada histogram price, dapat disimpulkan bahwa:

*   Peningkatan harga mobil sebanding dengan penurunan jumlah sampel
*   Rentang harga mobil cukup tinggi yaitu meningkat hingga \$162.000
*   Setengah harga mobil berada di bawah \$100.000
*   Distribusi harga miring ke kanan.

### Multivariate Analysis

##### Kolom Kategorical
"""

categorical_col = cars.select_dtypes(['object'])
for col in categorical_col:
  sns.catplot(x=col, y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=cars, palette="Set3")
  plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))

"""> Dengan mengamati harga relatif mobil terhadap fitur di atas, maka dapat disimpulkan bahwa:
*   pada fitur mark, harga mobil relatif bervariasi tergantung merk mobil, sehingga dapat disimpulkan bahwa fitur mark berpengaruh besar terhadap harga mobil
*   pada fitur fuel, harga mobil sangat tinggi pada dua kategori, yaitu hybrid dan electric sehingga dapat disimpulkan fitur fuel juga memiliki pengaruh besar terhadap price
*   pada fitur province, harga mobil cenderung tinggi pada beberapa kategori, sehingga dapat disimpulkan bahwa harga mobil dipengaruhi oleh fitur province
*   kesimpulan akhir, fitur kategori memiliki pengaruh besar terhadap price

##### Kolom Numerik

> Pairplot
"""

numerical_col = cars.select_dtypes(['int', 'float'])
sns.pairplot(numerical_col, diag_kind = 'kde')

"""> Heatmap """

plt.figure(figsize=(10, 8))
correlation_matrix = numerical_col.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""> Berdasarkan visualisasi pairplot dan heatmap di atas, maka dapat disimpulkan hanya fitur year dan mileage yang memiliki cukup korelasi dengan price, sehingga mari hapus saja fitur vol_engine."""

cars.drop(['vol_engine'], inplace=True, axis=1)
cars.head()

"""> Fyuuuhhh, akhirnya selesai juga EDA. Selanjutnya adalah data preparation

# Data Preparation

### Encoding Fitur Kategori
"""

cars = pd.concat([cars, pd.get_dummies(cars['mark'], prefix='mark')],axis=1)
cars = pd.concat([cars, pd.get_dummies(cars['fuel'], prefix='fuel')],axis=1)
cars = pd.concat([cars, pd.get_dummies(cars['province'], prefix='province')],axis=1)
cars.drop(['mark','fuel','province'], axis=1, inplace=True)
cars.head()

"""### Train-Test-Split"""

y = cars["price"]
X = cars.drop(["price"], axis=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.025, random_state = 123)

"""> Cek jumlah dataset"""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Standarisasi"""

numerical_features = ['year', 'mileage']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""> Cek mean dan standar deviasi menggunakan describe untuk memastikan nilainya 0 dan 1 setelah distandarisasi"""

X_train[numerical_features].describe().round(4)

"""# Model Development
> Pada kasus prediksi harga mobil ini, saya menggunakan tiga model, yaitu KNN, RandomForest, dan AdaBoost. Ketiga model tersebut nantinya akan dibandingkan dan model terbaik akan dijadikan sebagai model evaluasi. Sebelum melakukan model development, mari siapkan dataframe untuk analisis ketiga model tersebut.
"""

models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""### K-Nearest Neighbor"""

knn = KNeighborsRegressor(n_neighbors=15)
knn.fit(X_train, y_train)
models.loc['train_mse','KNN'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""### Random Forest"""

RF = RandomForestRegressor(n_estimators=50, max_depth=8, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""### AdaBoost"""

boosting = AdaBoostRegressor(learning_rate=0.1, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""# Evaluation

> Langkah pertama adalah melakukan standarisasi pada data test
"""

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""> Setelah ini, mari evaluasi ketiga model yang digunakan"""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
mse

"""> Visualisasi menggunakan barplot"""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""> Prediksi Model"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)